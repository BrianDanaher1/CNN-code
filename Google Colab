from google.colab import drive
drive.mount('/content/drive')

%tensorflow_version 2.x
import tensorflow as tf
from tensorflow.keras import datasets, layers, models

#Import helper libraries
import numpy as np
import matplotlib.pyplot as plt

tf.compat.v1.enable_eager_execution(
    config=None, device_policy=None, execution_mode=None
)

data_root='/content/drive/MyDrive/MA 490 data'

IMAGE_SHAPE = (600, 600)
TRAINING_DATA_DIR = str(data_root)
print(TRAINING_DATA_DIR);
datagen_kwargs = dict(rescale=1./255, validation_split=.2)

valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)
valid_generator = valid_datagen.flow_from_directory(TRAINING_DATA_DIR,subset="validation",shuffle=True,target_size=IMAGE_SHAPE,batch_size=44)
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)
train_generator = train_datagen.flow_from_directory(TRAINING_DATA_DIR,subset="training",shuffle=True,target_size=IMAGE_SHAPE,batch_size=176)

image_batch_train, label_batch_train = next(iter(train_generator))
print("Image batch shape: ", image_batch_train.shape)
print("Label batch shape: ", label_batch_train.shape)
dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])
dataset_labels = np.array([key.title() for key, value in dataset_labels])
print(dataset_labels)

#Rename
class_names = dataset_labels
train_images = image_batch_train
train_labels = label_batch_train

#Load and split dataset into training and testing images
from sklearn.model_selection import train_test_split
train_images, test_images, train_labels, test_labels = train_test_split(train_images, train_labels)

#train_images, test_images, train_labels, test_labels = tf.split(train_images, train_labels)

#Print out an example image
plt.figure()
plt.imshow(train_images[2])
plt.colorbar()
plt.grid(False)
plt.show

#Variable stride, imports

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Dec 17 09:33:13 2020

@author: lundmc
"""

"""
Hi ERAU team!

Below are the sections of code for the Variable Stride class, called MyLayer,
and its support function, CalcVSOutShape. I've left some comments in the codes, 
which may or may not be useful in helping you decipher what we're doing. 

There is good news and bad news- the bad news is that Python doesn't even make
my top 3 as far as preferred languages, so there is a lot of room for 
improvement in these codes. The good news is that they work, and you can 
accomplish a lot with this project, even if you never fully understand the 
codes.


As far as usage: 
    You will discover in your research of CNNs that the general structure for
creating a network in Keras/ Tensorflow is, depending on how you import 
packages, something along the lines of:
    
    model=Sequential()
    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
    model.add(MaxPooling2D((2, 2)))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    ... and so on
    
    
I have been adding in the Variable Stride layer at the very beginning of my 
network, so mine have started out with something like this:
    
    model=Sequential()
    model.add(MyLayer(self.input_shape, input_shape = self.input_shape))
    image_size=[int(model.output.shape[1]), int(model.output.shape[2])]
    model.add(Conv2D(32, (3, 3), activation='relu'))
    image_size=[int(model.output.shape[1]), int(model.output.shape[2])]
    ... and so on

I track the input and output shapes as a sanity check, which I find useful, but 
is not necessary. I also allow input_shape vary so I can use it with  different 
data sets, but you can hard code this for the retinopathy data.

Below is a list of packages I import and use to contstruct my network; you can 
see from the warnings that not all of them are used in the Variable Stride part 
of the codes. This is just a starting place. You will probably use different/ 
additional packages in the networks you create (hint: there are some good ones
out there for importing data and splitting it into training and testing sets).

Good luck!
Maggie Lund

"""

import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, BatchNormalization, Flatten, Layer
from keras.optimizers import Adam
import keras.callbacks
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import os, os.path
from keras import activations
from keras import backend as K
import tensorflow as tf

def CalcVSOutShape(input_shape,
                   step_v = [3, 1, 3],
                   step_h = [1, 5],
                   frac_v = [1/3, 1/3, 1/3],
                   frac_h = [1/4, 3/4]):
    #print('hhh', input_shape)
    (nx, ny,nz) = input_shape
    ## Compute the cumulative fractions of rows(v) / columns(h)
    cum_frac_v = np.cumsum(frac_v)
    cum_frac_h = np.cumsum(frac_h)
    
    #### Estimate the output shape of the image
    ## #?# the algorithm shifts after exceeding the threshold
    frac_bounds_v = cum_frac_v * (nx-0) - 1
    frac_bounds_h = cum_frac_h * (ny-0) - 1
    
    out_h = 0
    out_v = 0
    
    idx_low = 0

    for frac_idx in range(len(frac_h)):
        
        idx_span = min(frac_bounds_h[frac_idx], ny-3) - idx_low
        
        divisor_h, remainder_h = divmod(idx_span, step_h[frac_idx])

        out_h += int(divisor_h) + 1
        idx_low += (int(divisor_h) + 1) * step_h[frac_idx]
    
    idx_low = 0
    
    for frac_idx in range(len(frac_v)):
        idx_span = min(frac_bounds_v[frac_idx], nx-3) - idx_low
        
        divisor_v, remainder_v = divmod(idx_span, step_v[frac_idx])
    
        out_v += int(divisor_v) + 1
        idx_low += (int(divisor_v) + 1) * step_v[frac_idx]
        
    return (out_v, out_h, nz)

#Modified
class MyLayer(Layer):

    def __init__(self, 
                 _input_shape,
                 k1 =  np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]),
                 step_v = [3, 1, 3],
                 step_h = [1, 5],
                 frac_v = [1/3, 1/3, 1/3],
                 frac_h = [1/4, 3/4],
                 **kwargs): #output_dim?
        
        self._input_shape = _input_shape
        self.k1 = k1
        self.step_v = step_v
        self.step_h = step_h
        self.frac_v = frac_v
        self.frac_h = frac_h
        self.output_dim = CalcVSOutShape(_input_shape,
                   step_v = step_v,
                   step_h = step_h,
                   frac_v = frac_v,
                   frac_h = frac_h)
        
        super(MyLayer, self).__init__(**kwargs)

    ## needs output_dim and input_shape
        
    ## Might be done, do I need to stack/concatenate the results?
    def call(self, inputs):

        myimg = inputs #[0,:,:,:]
    
        (whatisthis,nx,ny,nz) = myimg.shape

        nx = int(nx)
        ny = int(ny)
        nz = int(nz)
        
        out_shape = CalcVSOutShape((nx, ny, nz),
                       step_v = self.step_v,
                       step_h = self.step_h,
                       frac_v = self.frac_v,
                       frac_h = self.frac_h)
        
        #print('predicted output shape', out_shape)

        try:
            batch_quant = int(whatisthis)
        except:
            
            print('placeholder tensor passed to call, pushing it forward in the desired output shape')
            newimg = myimg[:,:out_shape[0],:out_shape[1],:out_shape[2]]
            #print('77', newimg, newimg.shape, type(newimg))
            return newimg
        
        newimg = np.zeros((batch_quant,) + out_shape)    

        kernel = np.repeat(self.k1[:, :, np.newaxis], nz, axis=2)
    
        mystep_v = 0
        mystep_h = 0
        myfrac_v = 0
        myfrac_h = 0
        
        newrow = 0
        oldrow = 0
        oldcol = 0
        
        new_col_idx = 0
        new_row_idx = 0

        #Modified!
        while (oldrow < (nx-2)) and (new_row_idx < newimg.shape[1]): 
    
            while (oldcol < (ny-2)) and (new_col_idx < newimg.shape[2]):  
                temp = tf.keras.backend.get_value(myimg[0,oldrow:oldrow+3,oldcol:oldcol+3,:])
   
                temp *= kernel

                #print(newimg.shape)
                #print(new_row_idx, new_col_idx)
                #print(nx,ny)
                #print(newimg[0, new_row_idx, new_col_idx,:])
                #print(np.size(temp))
                #print(np.size(np.sum(temp,axis=new_row_idx)))
                #print(np.size(np.sum(np.sum(temp,axis=0),axis=0)))

                #newimg[new_row_idx, new_col_idx,:] =  np.sum(np.sum(temp,axis=0),axis=0)
                newimg[0, new_row_idx, new_col_idx,:] =  np.sum(np.sum(temp,axis=0),axis=0)


                if oldcol > (np.sum(self.frac_h[0:myfrac_h+1]) * nx - 1):
                    
                    mystep_h = mystep_h + 1  #?# mystep_h always equals myfrac_h
                    myfrac_h = myfrac_h + 1
                    
                oldcol = oldcol + self.step_h[mystep_h]
                
                new_col_idx += 1
                
            if oldrow > (np.sum(self.frac_v[0:myfrac_v+1]) * ny - 1):
                    
                mystep_v = mystep_v + 1  #?# mystep_v always equals myfrac_v
                myfrac_v = myfrac_v + 1 
                
            oldcol = 0
            mystep_h = 0
            myfrac_h = 0
            newrow = newrow + 1
            oldrow = oldrow + self.step_v[mystep_v]
            new_row_idx += 1
    
        return K.constant(newimg)

    ## DONE
    def compute_output_shape(self, input_shape):
        #assert isinstance(input_shape, list)
        
        working_shape_tuple = input_shape[1:]
        
        new_shape = CalcVSOutShape(working_shape_tuple,
                                   step_v = self.step_v,
                                   step_h = self.step_h,
                                   frac_v = self.frac_v,
                                   frac_h = self.frac_h)
        
        return (input_shape[0],) + tuple(new_shape)  # pre-pend the batch_size :: input_shape[0]

#Here is the actual network
#Note that there are dense layers and pooled layers

#Test 1

#This is the "convolutional base"
model = models.Sequential()
model.add(layers.Conv2D(32, (25, 25), activation='relu', input_shape=(600, 600, 3))) #32x32x3 pixels passing 32 3x3 filters over the data

image_size=[int(model.output.shape[1]), int(model.output.shape[2]), int(model.output.shape[3])]
model.add(MyLayer(_input_shape = image_size))

model.add(layers.Conv2D(64, (3, 3), activation='relu')) #Passing 64 3x3 filters over the image
model.add(layers.MaxPooling2D((2, 2))) #downsample
model.add(layers.Conv2D(64, (3, 3), activation='relu')) #Passing 64 3x3 filters over the image
model.add(layers.MaxPooling2D((2, 2))) #downsample
model.add(layers.Conv2D(64, (3, 3), activation='relu')) #Passing 64 3x3 filters over the image

#Now we add the dense layers
model.add(layers.Flatten())
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dense(1))

#Sanity check
model.summary()

#pip visualkeras
#import visualkeras
#visualkeras.layered_view(model).show() # display using your system viewer

#Train the model! (Note: takes a long time)

#model.compile(optimizer='adam',
              #loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              #metrics=['accuracy'],run_eagerly=True)

model.compile(optimizer='SGD',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'],run_eagerly=True)

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

history = model.fit(train_images, train_labels[:,0], epochs=1, 
                    validation_data=(test_images, test_labels[:,0]), batch_size=1)

test_loss, test_acc = model.evaluate(test_images, test_labels[:,0])
print(test_acc)

print(np.size(test_images)/(300*300*3))
test_loss, test_acc = model.evaluate(test_images, test_labels[:,0])
y_pred_keras = model.predict(test_images)

import sklearn

fpr_keras, tpr_keras, thresholds_keras = sklearn.metrics.roc_curve(test_labels[:,0],y_pred_keras)
auc = sklearn.metrics.roc_auc_score(test_labels[:,0],y_pred_keras)

plt.figure(1)
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.show()
